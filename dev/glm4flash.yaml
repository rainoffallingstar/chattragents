default:
  prompt: |
    {readLines(system.file('prompt/base.txt', package = 'chattr'))}
  provider: OpenAI - Chat Completions
  path: https://open.bigmodel.cn/api/paas/v4/chat/completions
  label: yi-34b-chat-0205 (01.AI)
  model: glm-4-flash
  max_data_files: 0
  max_data_frames: 0
  include_doc_contents: no
  include_history: yes
  system_msg: You are a helpful coding assistant
  model_arguments:
    temperature: 0.03
    max_tokens: 1000
    stream: yes
chat:
  prompt: |
    {readLines(system.file('prompt/base.txt', package = 'chattr'))}
    For code output, use RMarkdown code chunks
    Avoid all code chunk options
console:
  prompt: |
    {readLines(system.file('prompt/base.txt', package = 'chattr'))}
    For any line that is not code, prefix with a: #
    Keep each line of explanations to no more than 80 characters
    DO NOT use Markdown for the code
script:
  prompt: |-
    {readLines(system.file('prompt/base.txt', package = 'chattr'))}
    For any line that is not code, prefix with a: #
    Keep each line of explanations to no more than 80 characters
    DO NOT use Markdown for the code
